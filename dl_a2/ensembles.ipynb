{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensembles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajbircit/assignments/blob/main/dl_a2/ensembles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbYaJtuDaTSE"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbaCPhN3m9aK"
      },
      "source": [
        "#### Show the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB1IYEiCVI31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978546c8-c955-48fe-8c9e-3d80503e7c55"
      },
      "source": [
        "!nvidia-smi\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!df -h\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!free -m\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!lscpu\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "! ps -eo pmem,pcpu,vsize,pid,cmd | sort -k 1 -nr | head -5\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 24 11:02:08 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          69G   39G   30G  57% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "tmpfs           6.4G   24K  6.4G   1% /var/colab\n",
            "/dev/sda1        75G   41G   35G  54% /opt/bin\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          13021         578       10402           0        2040       12165\n",
            "Swap:             0           0           0\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2199.998\n",
            "BogoMIPS:            4399.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            " 0.8 15.8 690496      58 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-2fe4cf08-92e2-4760-ad26-e32644e6a44f.json\n",
            " 0.4  5.2 193900      47 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --LargeFileManager.delete_to_trash=False --MappingKernelManager.root_dir=\"/content\"\n",
            " 0.3  1.9 337004       1 /tools/node/bin/node /datalab/web/app.js\n",
            " 0.1  0.2 127392      78 /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/debugpy/adapter --for-server 40405 --host 127.0.0.1 --port 24180 --server-access-token dfb76d52e3368f712fc61bcc94fa12cb6f73cefa0921692c8efcf24cbc80817d\n",
            "%MEM %CPU    VSZ     PID CMD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhKgZdLnDXe"
      },
      "source": [
        "#### Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-qJFYSyXipf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import logging\n",
        "import sys\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import zipfile\n",
        "import h5py\n",
        "import gc\n",
        "import IPython\n",
        "\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "root = logging.getLogger()\n",
        "root.setLevel(logging.INFO)\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "root.addHandler(handler)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5dT_-3nTqYe"
      },
      "source": [
        "#### Mount Google Drive And Copy Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrZWOv9fTsF2",
        "outputId": "5f6eb3bd-1922-4335-afb2-43a070677b34"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if (os.path.exists(\"/root/imagedata\")):\n",
        "    ret = shutil.rmtree(\"/root/imagedata\")\n",
        "os.mkdir(\"/root/imagedata\")\n",
        "shutil.copyfile( \\\n",
        "    \"/content/gdrive/MyDrive/DeepLearningAssignment2/earth_data.zip\",\n",
        "    \"/root/imagedata/earth_data.zip\")\n",
        "\n",
        "!cd /root/imagedata && unzip earth_data.zip && rm -f earth_data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Archive:  earth_data.zip\n",
            "  inflating: earth_data.h5           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hK1gQ5CV1i-"
      },
      "source": [
        "## Code to plot graphs and remember histories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy4Y9ACqfea7"
      },
      "source": [
        "class Entry:\n",
        "    def __init__(self, loss, val_loss, accuracy, val_accuracy, best_accuracy, best_loss):\n",
        "        self.loss = loss\n",
        "        self.val_loss = val_loss\n",
        "        self.accuracy = accuracy\n",
        "        self.val_accuracy = val_accuracy\n",
        "        self.best_accuracy = best_accuracy\n",
        "        self.best_loss = best_loss\n",
        "\n",
        "class Plot:\n",
        "    def __init__(self):\n",
        "        self.history = {}\n",
        "        self.colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:blue', \\\n",
        "                       'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \\\n",
        "                       'tab:brown', 'tab:pink', 'tab:olive', 'tab:cyan']\n",
        "\n",
        "    def plot_history(self, history, N_EPOCHS, name, show=True):\n",
        "        if show:\n",
        "            N_EPOCHS = len(history.history[\"loss\"])\n",
        "            plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "            plt.xticks(np.arange(0, N_EPOCHS+1, 1.0))\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"loss\"], label=\"train loss\", color='blue', linestyle='solid')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"val_loss\"], label=\"val loss\", color='blue', linestyle='dashdot')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"accuracy\"], label=\"train acc\", color='red', linestyle='solid')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"val_accuracy\"], label=\"val acc\", color='red', linestyle='dashdot')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        best_val_acc = max(history.history['val_accuracy'])\n",
        "        index_best_val_accuracy = history.history['val_accuracy'].index(best_val_acc)\n",
        "        best_val_loss = min(history.history['val_loss'])\n",
        "        index_best_val_loss = history.history['val_loss'].index(best_val_loss)\n",
        "        if show:\n",
        "            print(f\"Best validation accuracy: {best_val_acc}, epoch = {index_best_val_accuracy}\")\n",
        "            print(f\"Best validation loss: {best_val_loss}, epoch = {index_best_val_loss}\")\n",
        "        entry = Entry(\\\n",
        "                      loss=history.history[\"loss\"],\\\n",
        "                      val_loss=history.history[\"val_loss\"],\\\n",
        "                      accuracy=history.history[\"accuracy\"],\\\n",
        "                      val_accuracy=history.history[\"val_accuracy\"],\\\n",
        "                      best_accuracy=best_val_acc,\n",
        "                      best_loss=best_val_loss)\n",
        "        self.history[name] = entry\n",
        "        gc.collect()\n",
        "\n",
        "    def superplot(self):\n",
        "        i = 0\n",
        "        plt.rcParams[\"figure.figsize\"] = [30, 10]\n",
        "        fig, ax = plt.subplots(1, 2)\n",
        "        def innerplot(self, ax, arr, text, linest):\n",
        "            ax.plot(np.arange(0, len(arr)), arr, label=text, color=self.colors[i], linestyle=linest)\n",
        "        for name, entry in self.history.items():\n",
        "            innerplot(self, ax[0], entry.loss, f\"{name}-loss\", \"solid\")\n",
        "            innerplot(self, ax[0], entry.val_loss, f\"{name}-val-loss\", \"dashdot\")\n",
        "            innerplot(self, ax[1], entry.accuracy, f\"{name}-accuracy\", \"solid\")\n",
        "            innerplot(self, ax[1], entry.val_accuracy, f\"{name}-val-accuracy\", \"dashdot\")\n",
        "            i += 1\n",
        "        ax[0].legend()\n",
        "        ax[1].legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plot = Plot()\n",
        "plot_adaptive = Plot()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7YJVg4Z8j3"
      },
      "source": [
        "## Extract train and test instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opVq7JewaAGA",
        "outputId": "307b1235-8d16-4395-840b-c3d06426e609"
      },
      "source": [
        "def loadDataH5():\n",
        "    with h5py.File('/root/imagedata/earth_data.h5','r') as hf:\n",
        "        trainX = np.array(hf.get('trainX'))\n",
        "        trainY = np.array(hf.get('trainY'))\n",
        "        valX = np.array(hf.get('valX'))\n",
        "        valY = np.array(hf.get('valY'))\n",
        "        print (trainX.shape,trainY.shape)\n",
        "        print (valX.shape,valY.shape)\n",
        "        return trainX, trainY, valX, valY\n",
        "\n",
        "trainX, trainY, valX, valY = loadDataH5()\n",
        "trainX = trainX / 255.0\n",
        "valX = valX / 255.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19200, 64, 64, 3) (19200,)\n",
            "(4800, 64, 64, 3) (4800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewCcmX_SWH4W"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLKhKGMRWNfT"
      },
      "source": [
        "def decay_after_runs(N):\n",
        "    NRUNS = N\n",
        "    # We're sneaking this in, since this will be called at every epoch\n",
        "    # it also gives us a good way to force calls to gc() within the fit function\n",
        "    gc.collect()\n",
        "    def learning_rate_scheduler(epoch, lr):\n",
        "        if NRUNS < 0 or epoch < NRUNS:\n",
        "            return lr\n",
        "        else:\n",
        "            print(f\"Learning Rate: {lr} --> {lr * tf.math.exp(-1.0)}\")\n",
        "            return lr * tf.math.exp(-0.1)\n",
        "    return learning_rate_scheduler\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(decay_after_runs(20))\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\\\n",
        "                                                  monitor='val_loss',\\\n",
        "                                                  patience=3,\n",
        "                                                  verbose=1,\n",
        "                                                  mode='auto')\n",
        "early_stopping2 = tf.keras.callbacks.EarlyStopping(\\\n",
        "                                                  monitor='val_loss',\\\n",
        "                                                  patience=10,\n",
        "                                                  verbose=1,\n",
        "                                                  mode='auto')\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\\\n",
        "                                                 monitor='val_loss',\\\n",
        "                                                 factor=0.5,\\\n",
        "                                                 patience=3,\\\n",
        "                                                 min_lr=0.001)\n",
        "\n",
        "term_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
        "\n",
        "def get_checkpoint_callback(name):\n",
        "    checkpoint_filepath = f\"/content/gdrive/MyDrive/DeepLearningAssignment2/checkpoints-{name}-checkpoint\"\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "    return model_checkpoint_callback\n",
        "\n",
        "\n",
        "def get_callbacks_decay_after(N, name=None):\n",
        "    if N == -2:\n",
        "        callback_array = [\\\n",
        "                        tf.keras.callbacks.LearningRateScheduler(\\\n",
        "                                                    decay_after_runs(-1)),\n",
        "                        early_stopping2,\n",
        "                        term_on_nan,\n",
        "                        ]\n",
        "    else:\n",
        "        callback_array = [\\\n",
        "                        tf.keras.callbacks.LearningRateScheduler(\\\n",
        "                                                    decay_after_runs(N)),\n",
        "                        early_stopping,\n",
        "                        term_on_nan,\n",
        "                        ]\n",
        "    if N > 0:\n",
        "        callback_array.append(reduce_lr)\n",
        "    if None != name:\n",
        "        callback_array.append(get_checkpoint_callback(name))\n",
        "    return callback_array"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWZ5Iw4skLdB"
      },
      "source": [
        "# Question 1 Part A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVwezZ7dkTt_"
      },
      "source": [
        "## 1. Build a Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwizNaadbIpk",
        "outputId": "8452400f-c869-4462-f863-69753ff98a5f"
      },
      "source": [
        "import random\n",
        "plot2 = Plot()\n",
        "class BaselineShallowNet:\n",
        "    @staticmethod\n",
        "    def build(inshape, nlabels):\n",
        "        inputShape = trainX[0].shape\n",
        "        model = tf.keras.Sequential(name=\"BaseLineShallowNet\")\n",
        "        model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', \\\n",
        "                  input_shape=inshape, activation='relu'))\n",
        "        model.add(tf.keras.layers.MaxPooling2D(2, 2,))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(nlabels, activation='softmax'))\n",
        "        plot = tf.keras.utils.plot_model(model, show_shapes=True, \\\n",
        "                                         expand_nested=True)\n",
        "        IPython.display.display(plot)\n",
        "        print(model.summary())\n",
        "        return model\n",
        "\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def get_conv_layer(depth, inshape=None):\n",
        "        out_layers = []\n",
        "        filter_size = random.choice([3, 4, 5])\n",
        "        stride_size = 1 #random.choice([1, 2, 3])\n",
        "        stride_size = (stride_size, stride_size, )\n",
        "        filter_shape = tuple([filter_size, filter_size,])\n",
        "        act_fn = random.choice(['tanh', 'relu', 'sigmoid', 'selu', 'elu'])\n",
        "        pd = 'same'\n",
        "\n",
        "        if None != inshape:\n",
        "            conv_layer = tf.keras.layers.Conv2D(\\\n",
        "                                                depth,\\\n",
        "                                                filter_shape,\\\n",
        "                                                padding=pd,\\\n",
        "                                                input_shape=inshape,\\\n",
        "                                                activation=act_fn)\n",
        "        else:\n",
        "            conv_layer = tf.keras.layers.Conv2D(\\\n",
        "                                                depth,\\\n",
        "                                                filter_shape,\\\n",
        "                                                padding=pd,\\\n",
        "                                                activation=act_fn)\n",
        "        out_layers.append(conv_layer)\n",
        "\n",
        "        if random.choice([True, False]):\n",
        "            pool_size = random.choice([2, 3, 4])\n",
        "            out_layers.append(tf.keras.layers.MaxPooling2D(pool_size, pool_size,))\n",
        "        \n",
        "        if random.choice([True, False]):\n",
        "            out_layers.append(tf.keras.layers.SpatialDropout2D(0.25))\n",
        "\n",
        "        return out_layers\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_model(inshp, nlabels:int, modelname:str):\n",
        "        layer_neurons = []\n",
        "        n_conv_layers = random.choice([1, 2, 3,])\n",
        "        layer_depth = sorted([\\\n",
        "                random.choice([32, 64, 128, 256, 512, 1024, 2048]) \\\n",
        "                    for _ in range(n_conv_layers)])\n",
        "\n",
        "        model = tf.keras.Sequential(name=modelname)\n",
        "        for lyr in ModelFactory.get_conv_layer(layer_depth[0], inshp):\n",
        "            model.add(lyr)\n",
        "        \n",
        "        for d in layer_depth[1:]:\n",
        "            for lyr in ModelFactory.get_conv_layer(d, inshape=None):\n",
        "                model.add(lyr)\n",
        "        \n",
        "        #plot = tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)\n",
        "        #IPython.display.display(plot)\n",
        "        print(model.summary())\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "n_classes = len(np.unique(np.concatenate((trainY, valY))))\n",
        "model = ModelFactory.generate_model(trainX[0].shape, n_classes, \"thismodel\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"thismodel\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_65 (Conv2D)           (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "spatial_dropout2d_24 (Spatia (None, 64, 64, 64)        0         \n",
            "=================================================================\n",
            "Total params: 1,792\n",
            "Trainable params: 1,792\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B53vrfswjhOH",
        "outputId": "feb23ed3-d588-4451-8b7a-cf2933c26c9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(random.choice([5, 4, 3, 2, 1]))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnSso758jjmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}