{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensembles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajbircit/assignments/blob/main/dl_a2/ensembles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbYaJtuDaTSE"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbaCPhN3m9aK"
      },
      "source": [
        "#### Show the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB1IYEiCVI31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b143ed95-8b04-4586-fac4-5e550b2e6ddd"
      },
      "source": [
        "!nvidia-smi\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!df -h\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!free -m\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!lscpu\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "! ps -eo pmem,pcpu,vsize,pid,cmd | sort -k 1 -nr | head -5\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 24 14:12:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          69G   39G   30G  57% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "/dev/sda1        75G   41G   35G  54% /opt/bin\n",
            "tmpfs           6.4G   24K  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          13021         586       10393           0        2041       12159\n",
            "Swap:             0           0           0\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2199.998\n",
            "BogoMIPS:            4399.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            " 0.8  2.2 692288      62 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-aac5aeeb-fff9-4d1c-8257-26bb47e3ee13.json\n",
            " 0.4  1.0 193900      50 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --LargeFileManager.delete_to_trash=False --MappingKernelManager.root_dir=\"/content\"\n",
            " 0.3  0.8 339564       1 /tools/node/bin/node /datalab/web/app.js\n",
            " 0.1  0.0 127392      82 /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/debugpy/adapter --for-server 32907 --host 127.0.0.1 --port 24724 --server-access-token 36022f122207ff1d5916b5e662979c63c2ba1016910ce86dab475880564c8f1a\n",
            "%MEM %CPU    VSZ     PID CMD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhKgZdLnDXe"
      },
      "source": [
        "#### Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-qJFYSyXipf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import logging\n",
        "import sys\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import zipfile\n",
        "import h5py\n",
        "import gc\n",
        "import IPython\n",
        "\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "root = logging.getLogger()\n",
        "root.setLevel(logging.INFO)\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "root.addHandler(handler)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5dT_-3nTqYe"
      },
      "source": [
        "#### Mount Google Drive And Copy Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrZWOv9fTsF2",
        "outputId": "32c03c9a-2ca1-4658-f105-2a4f606329ab"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if (os.path.exists(\"/root/imagedata\")):\n",
        "    ret = shutil.rmtree(\"/root/imagedata\")\n",
        "os.mkdir(\"/root/imagedata\")\n",
        "shutil.copyfile( \\\n",
        "    \"/content/gdrive/MyDrive/DeepLearningAssignment2/earth_data.zip\",\n",
        "    \"/root/imagedata/earth_data.zip\")\n",
        "\n",
        "!cd /root/imagedata && unzip earth_data.zip && rm -f earth_data.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Archive:  earth_data.zip\n",
            "  inflating: earth_data.h5           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hK1gQ5CV1i-"
      },
      "source": [
        "## Code to plot graphs and remember histories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy4Y9ACqfea7"
      },
      "source": [
        "class Entry:\n",
        "    def __init__(self, loss, val_loss, accuracy, val_accuracy, best_accuracy, best_loss):\n",
        "        self.loss = loss\n",
        "        self.val_loss = val_loss\n",
        "        self.accuracy = accuracy\n",
        "        self.val_accuracy = val_accuracy\n",
        "        self.best_accuracy = best_accuracy\n",
        "        self.best_loss = best_loss\n",
        "\n",
        "class Plot:\n",
        "    def __init__(self):\n",
        "        self.history = {}\n",
        "        self.colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:blue', \\\n",
        "                       'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \\\n",
        "                       'tab:brown', 'tab:pink', 'tab:olive', 'tab:cyan']\n",
        "\n",
        "    def plot_history(self, history, N_EPOCHS, name, show=True):\n",
        "        if show:\n",
        "            N_EPOCHS = len(history.history[\"loss\"])\n",
        "            plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "            plt.xticks(np.arange(0, N_EPOCHS+1, 1.0))\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"loss\"], label=\"train loss\", color='blue', linestyle='solid')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"val_loss\"], label=\"val loss\", color='blue', linestyle='dashdot')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"accuracy\"], label=\"train acc\", color='red', linestyle='solid')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"val_accuracy\"], label=\"val acc\", color='red', linestyle='dashdot')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        best_val_acc = max(history.history['val_accuracy'])\n",
        "        index_best_val_accuracy = history.history['val_accuracy'].index(best_val_acc)\n",
        "        best_val_loss = min(history.history['val_loss'])\n",
        "        index_best_val_loss = history.history['val_loss'].index(best_val_loss)\n",
        "        if show:\n",
        "            print(f\"Best validation accuracy: {best_val_acc}, epoch = {index_best_val_accuracy}\")\n",
        "            print(f\"Best validation loss: {best_val_loss}, epoch = {index_best_val_loss}\")\n",
        "        entry = Entry(\\\n",
        "                      loss=history.history[\"loss\"],\\\n",
        "                      val_loss=history.history[\"val_loss\"],\\\n",
        "                      accuracy=history.history[\"accuracy\"],\\\n",
        "                      val_accuracy=history.history[\"val_accuracy\"],\\\n",
        "                      best_accuracy=best_val_acc,\n",
        "                      best_loss=best_val_loss)\n",
        "        self.history[name] = entry\n",
        "        gc.collect()\n",
        "\n",
        "    def superplot(self):\n",
        "        i = 0\n",
        "        plt.rcParams[\"figure.figsize\"] = [30, 10]\n",
        "        fig, ax = plt.subplots(1, 2)\n",
        "        def innerplot(self, ax, arr, text, linest):\n",
        "            ax.plot(np.arange(0, len(arr)), arr, label=text, color=self.colors[i], linestyle=linest)\n",
        "        for name, entry in self.history.items():\n",
        "            innerplot(self, ax[0], entry.loss, f\"{name}-loss\", \"solid\")\n",
        "            innerplot(self, ax[0], entry.val_loss, f\"{name}-val-loss\", \"dashdot\")\n",
        "            innerplot(self, ax[1], entry.accuracy, f\"{name}-accuracy\", \"solid\")\n",
        "            innerplot(self, ax[1], entry.val_accuracy, f\"{name}-val-accuracy\", \"dashdot\")\n",
        "            i += 1\n",
        "        ax[0].legend()\n",
        "        ax[1].legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7YJVg4Z8j3"
      },
      "source": [
        "## Extract train and test instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opVq7JewaAGA",
        "outputId": "8e9f614e-1fea-465c-9360-7a3f8b4be5a3"
      },
      "source": [
        "def loadDataH5():\n",
        "    with h5py.File('/root/imagedata/earth_data.h5','r') as hf:\n",
        "        trainX = np.array(hf.get('trainX'))\n",
        "        trainY = np.array(hf.get('trainY'))\n",
        "        valX = np.array(hf.get('valX'))\n",
        "        valY = np.array(hf.get('valY'))\n",
        "        print (trainX.shape,trainY.shape)\n",
        "        print (valX.shape,valY.shape)\n",
        "        return trainX, trainY, valX, valY\n",
        "\n",
        "trainX, trainY, valX, valY = loadDataH5()\n",
        "trainX = trainX / 255.0\n",
        "valX = valX / 255.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19200, 64, 64, 3) (19200,)\n",
            "(4800, 64, 64, 3) (4800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewCcmX_SWH4W"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLKhKGMRWNfT"
      },
      "source": [
        "def decay_after_runs(N):\n",
        "    NRUNS = N\n",
        "    # We're sneaking this in, since this will be called at every epoch\n",
        "    # it also gives us a good way to force calls to gc() within the fit function\n",
        "    gc.collect()\n",
        "    def learning_rate_scheduler(epoch, lr):\n",
        "        if NRUNS < 0 or epoch < NRUNS:\n",
        "            return lr\n",
        "        else:\n",
        "            print(f\"Learning Rate: {lr} --> {lr * tf.math.exp(-1.0)}\")\n",
        "            return lr * tf.math.exp(-0.1)\n",
        "    return learning_rate_scheduler\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(decay_after_runs(20))\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\\\n",
        "                                                  monitor='val_loss',\\\n",
        "                                                  patience=3,\n",
        "                                                  verbose=1,\n",
        "                                                  mode='auto')\n",
        "early_stopping2 = tf.keras.callbacks.EarlyStopping(\\\n",
        "                                                  monitor='val_loss',\\\n",
        "                                                  patience=10,\n",
        "                                                  verbose=1,\n",
        "                                                  mode='auto')\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\\\n",
        "                                                 monitor='val_loss',\\\n",
        "                                                 factor=0.5,\\\n",
        "                                                 patience=3,\\\n",
        "                                                 min_lr=0.001)\n",
        "\n",
        "term_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
        "\n",
        "DRIVE_FOLDER = \"/content/gdrive/MyDrive/DeepLearningAssignment2\"\n",
        "\n",
        "def get_checkpoint_callback(name):\n",
        "    checkpoint_filepath = f\"{DRIVE_FOLDER}/ckp-{name}\"\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "    return model_checkpoint_callback\n",
        "\n",
        "\n",
        "def get_callbacks_decay_after(N, name=None):\n",
        "    if N == -2:\n",
        "        callback_array = [\\\n",
        "                        tf.keras.callbacks.LearningRateScheduler(\\\n",
        "                                                    decay_after_runs(-1)),\n",
        "                        early_stopping2,\n",
        "                        term_on_nan,\n",
        "                        ]\n",
        "    else:\n",
        "        callback_array = [\\\n",
        "                        tf.keras.callbacks.LearningRateScheduler(\\\n",
        "                                                    decay_after_runs(N)),\n",
        "                        early_stopping,\n",
        "                        term_on_nan,\n",
        "                        ]\n",
        "    if N > 0:\n",
        "        callback_array.append(reduce_lr)\n",
        "    if None != name:\n",
        "        callback_array.append(get_checkpoint_callback(name))\n",
        "    return callback_array"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWZ5Iw4skLdB"
      },
      "source": [
        "# Question 1 Part A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVwezZ7dkTt_"
      },
      "source": [
        "## 1. Build a model generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwizNaadbIpk"
      },
      "source": [
        "import random\n",
        "import gc\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def get_conv_layer(depth, inshape=None, force_stride_size=False):\n",
        "        out_layers = []\n",
        "        filter_size = random.choice([2, 3, 4, 5])\n",
        "        stride_size = random.choice([1, 2, 3])\n",
        "        stride_size = stride_size if stride_size < filter_size else filter_size\n",
        "\n",
        "        # In case there is an exception, the caller will\n",
        "        # set this and call again\n",
        "        stride_size = 1 if force_stride_size else stride_size\n",
        "\n",
        "        stride_size = (stride_size, stride_size, )\n",
        "        filter_shape = tuple([filter_size, filter_size,])\n",
        "        act_fn = random.choice(['tanh', 'relu', 'sigmoid', 'selu', 'elu'])\n",
        "        pd = random.choice(['same', 'valid'])\n",
        "\n",
        "        if None != inshape:\n",
        "            conv_layer = tf.keras.layers.Conv2D(\\\n",
        "                                                depth,\\\n",
        "                                                filter_shape,\\\n",
        "                                                padding=pd,\\\n",
        "                                                input_shape=inshape,\\\n",
        "                                                strides=stride_size,\\\n",
        "                                                activation=act_fn)\n",
        "        else:\n",
        "            conv_layer = tf.keras.layers.Conv2D(\\\n",
        "                                                depth,\\\n",
        "                                                filter_shape,\\\n",
        "                                                padding=pd,\\\n",
        "                                                strides=stride_size,\\\n",
        "                                                activation=act_fn)\n",
        "        out_layers.append(conv_layer)\n",
        "\n",
        "        if random.choice([True, False]):\n",
        "            pool_size = random.choice([2, 3, 4])\n",
        "            out_layers.append(tf.keras.layers.MaxPooling2D(\\\n",
        "                                                           pool_size,\\\n",
        "                                                           pool_size,))\n",
        "        \n",
        "        if random.choice([True, False]):\n",
        "            out_layers.append(tf.keras.layers.SpatialDropout2D(0.25))\n",
        "\n",
        "        return out_layers\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_model_internal(inshp, nlabels:int, modelname:str, fss:bool):\n",
        "        layer_neurons = []\n",
        "        n_conv_layers = random.choice([1, 2, 3,])\n",
        "        layer_depth = sorted([\\\n",
        "                random.choice([32, 64, 128, 256, 512, 1024]) \\\n",
        "                    for _ in range(n_conv_layers)])\n",
        "\n",
        "        for i in range(1, len(layer_depth)):\n",
        "            if layer_depth[i] <= layer_depth[i-1]:\n",
        "                layer_depth[i] = 2 * layer_depth[i-1]\n",
        "\n",
        "        # Add the first Convolutional layer\n",
        "        model = tf.keras.Sequential(name=modelname)\n",
        "        for lyr in ModelFactory.get_conv_layer(layer_depth[0], inshp, force_stride_size=fss):\n",
        "            model.add(lyr)\n",
        "        \n",
        "        # Add zero or more additional convoluationa layer\n",
        "        for d in layer_depth[1:]:\n",
        "            for lyr in ModelFactory.get_conv_layer(d, inshape=None, force_stride_size=fss):\n",
        "                model.add(lyr)\n",
        "\n",
        "        # Flatten\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "        # Add zero or more dense layers\n",
        "        n_dense = random.choice([0, 1, 2])\n",
        "        for _ in range(n_dense - 1):\n",
        "            act_fn = random.choice(['tanh', 'relu', 'sigmoid', 'selu', 'elu'])\n",
        "            layer = tf.keras.layers.Dense(\\\n",
        "                                random.choice([32, 64, 128, 256, 512]),\n",
        "                                activation=act_fn)\n",
        "            model.add(layer)\n",
        "            if random.choice([True, False]):\n",
        "                layer = tf.keras.layers.Dropout(0.25)\n",
        "                model.add(layer)\n",
        "        \n",
        "        # Add the final Dense layer\n",
        "        model.add(tf.keras.layers.Dense(nlabels, activation='softmax'))\n",
        "        \n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def print_model(model):\n",
        "        plot = tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)\n",
        "        IPython.display.display(plot)\n",
        "        print(model.summary())\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_model_size(inshp:tuple, nlabels:int, modelname:str, max_params:int):\n",
        "        if (-1 == max_params):\n",
        "            try:\n",
        "                model = ModelFactory.generate_model_internal(\\\n",
        "                                                            inshp,\\\n",
        "                                                            nlabels,\\\n",
        "                                                            modelname,\\\n",
        "                                                            False)\n",
        "            except:\n",
        "                model = ModelFactory.generate_model_internal(\\\n",
        "                                                            inshp,\\\n",
        "                                                            nlabels,\\\n",
        "                                                            modelname,\\\n",
        "                                                            True)\n",
        "            ModelFactory.print_model(model)\n",
        "            return model\n",
        "        else:\n",
        "            # Make 10 attempts to generate a model with the number of\n",
        "            # trainable params less than the one specified\n",
        "            for i in range(10):\n",
        "                gc.collect()\n",
        "                logging.debug(f\"Attempt {i}\")\n",
        "                try:\n",
        "                    model = ModelFactory.generate_model_internal(\\\n",
        "                                                                inshp,\\\n",
        "                                                                nlabels,\\\n",
        "                                                                modelname,\n",
        "                                                                False)\n",
        "                except:\n",
        "                    model = ModelFactory.generate_model_internal(\\\n",
        "                                                                inshp,\\\n",
        "                                                                nlabels,\\\n",
        "                                                                modelname,\n",
        "                                                                True)\n",
        "                if model.count_params() < max_params:\n",
        "                    ModelFactory.print_model(model)\n",
        "                    gc.collect()\n",
        "                    return model\n",
        "\n",
        "                gc.collect()\n",
        "            return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def generate_model(inshp:tuple, nlabels:int, modelname:str, max_params:int):\n",
        "        \"\"\"\n",
        "        Tries to make a model with the number of trainable params less\n",
        "        than the specified number. If it is not able to do so, it will\n",
        "        create a model with a greater number regardless\n",
        "        \"\"\"\n",
        "        model = ModelFactory.generate_model_size(\\\n",
        "                                                 inshp,\\\n",
        "                                                 nlabels,\\\n",
        "                                                 modelname,\\\n",
        "                                                 max_params)\n",
        "        if None == model:\n",
        "            model = ModelFactory.generate_model_size(\\\n",
        "                                                     inshp,\\\n",
        "                                                     nlabels,\\\n",
        "                                                     modelname,\\\n",
        "                                                     -1)\n",
        "        return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNCqleXXKLq-"
      },
      "source": [
        "# Generate the Base Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTDI6AqQKDz0"
      },
      "source": [
        "\n",
        "def get_formatted_json(jsonstr):\n",
        "    j = json.loads(jsonstr)\n",
        "    return json.dumps(j, indent=4)\n",
        "\n",
        "get_model_name = lambda n : f\"ensemble-base-model-{n}\"\n",
        "get_model_json_filename = lambda n : f\"save-ensemble-base-model-{n}.json\"\n",
        "\n",
        "import json\n",
        "def generate_base_models(n_models):\n",
        "    n_classes = len(np.unique(np.concatenate((trainY, valY))))\n",
        "    for i in range(n_models):\n",
        "        modelname = get_model_name(i)\n",
        "        filename = get_model_json_filename(i)\n",
        "        model = ModelFactory.generate_model(trainX[0].shape, n_classes, modelname, 9_500_000)\n",
        "        model_json = model.to_json()\n",
        "        with open(f\"{DRIVE_FOLDER}/{filename}\", \"w\") as f:\n",
        "            f.write(get_formatted_json(model_json))\n",
        "            f.close()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qICfAnC2OOZg"
      },
      "source": [
        "# Train each model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU4ACEwVOMcO"
      },
      "source": [
        "def train_model_internal(model, plot):\n",
        "    print(model.summary())\n",
        "    print()\n",
        "    N_EPOCHS = 2\n",
        "    model.compile(optimizer='adam', \\\n",
        "              loss='sparse_categorical_crossentropy', \\\n",
        "              metrics=['accuracy'])\n",
        "    if model.count_params() < 1_500_000:\n",
        "        print(\"Using decay of learning reate\")\n",
        "        cb = get_callbacks_decay_after(5, model.name)\n",
        "    else:\n",
        "        print(\"Avoiding decay of learning reate\")\n",
        "        cb = get_callbacks_decay_after(-1, model.name)\n",
        "    history = model.fit(trainX, trainY, \\\n",
        "                    validation_data=(valX, valY),\\\n",
        "                    batch_size=32,\\\n",
        "                    epochs=N_EPOCHS,\n",
        "                    callbacks=cb)\n",
        "    if plot:\n",
        "        plot.plot_history(history, 100, model.name)\n",
        "\n",
        "def train_model(i, plot):\n",
        "    print('=' * 80)\n",
        "    print('=' * 80)\n",
        "    print(f\"Training model {i}\")\n",
        "    print()\n",
        "    fname = get_model_json_filename(i)\n",
        "    fname = f\"{DRIVE_FOLDER}/{fname}\"\n",
        "    with open(fname, \"r\") as f:\n",
        "        jsonstr = f.read()\n",
        "        model = tf.keras.models.model_from_json(jsonstr)\n",
        "        train_model_internal(model, plot)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23ULZugvX-Fi"
      },
      "source": [
        "def load_model(n):\n",
        "    fname = get_model_json_filename(n)\n",
        "    fname = f\"{DRIVE_FOLDER}/{fname}\"\n",
        "    with open(fname, \"r\") as f:\n",
        "        jsonstr = f.read()\n",
        "        model = tf.keras.models.model_from_json(jsonstr)\n",
        "        model.compile(optimizer='adam', \\\n",
        "              loss='sparse_categorical_crossentropy', \\\n",
        "              metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def load_model_weight(model, n):\n",
        "    weight_file = f\"{DRIVE_FOLDER}/ckp-{model.name}\"\n",
        "    model.load_weights(weight_file)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i6gkAITGsAl"
      },
      "source": [
        "N_BASE_MODELS = 10\n",
        "def main():\n",
        "    plot = Plot()\n",
        "    #generate_base_models(N_BASE_MODELS)\n",
        "    #for i in range(N_BASE_MODELS):\n",
        "    #    train_model(i, plot)\n",
        "    for i in range(N_BASE_MODELS):\n",
        "        model = load_model(i)\n",
        "        loss, acc = model.evaluate(valX, valY, verbose=0)\n",
        "        print(f\"{i}       {loss}        {acc}\")\n",
        "        load_model_weight(model, i)\n",
        "        loss, acc = model.evaluate(valX, valY, verbose=0)\n",
        "        print(f\"{i}       {loss}        {acc}\")\n",
        "        print()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otFamfCBK11G",
        "outputId": "2977377c-5fa3-4573-d698-6649666e9998"
      },
      "source": [
        "main()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "2021-04-24 15:08:32,492 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "2021-04-24 15:08:32,494 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "2021-04-24 15:08:32,499 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "2021-04-24 15:08:32,502 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "2021-04-24 15:08:32,507 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "2021-04-24 15:08:32,511 - tensorflow - WARNING - A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "0       2.203148603439331        0.13479167222976685\n",
            "0       1.0480611324310303        0.6210416555404663\n",
            "\n",
            "1       2.1956984996795654        0.11999999731779099\n",
            "1       0.9507529735565186        0.6656249761581421\n",
            "\n",
            "2       2.1924586296081543        0.125\n",
            "2       1.0552833080291748        0.6089583039283752\n",
            "\n",
            "3       2.195460319519043        0.11562500149011612\n",
            "3       1.135549783706665        0.6102083325386047\n",
            "\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "2021-04-24 15:08:57,271 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "2021-04-24 15:08:57,275 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "2021-04-24 15:08:57,280 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "2021-04-24 15:08:57,284 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "2021-04-24 15:08:57,287 - tensorflow - WARNING - Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "2021-04-24 15:08:57,291 - tensorflow - WARNING - A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "4       2.375887155532837        0.125\n",
            "4       2.3505725860595703        0.29083332419395447\n",
            "\n",
            "5       2.296746253967285        0.10916666686534882\n",
            "5       1.7633461952209473        0.3227083384990692\n",
            "\n",
            "6       2.2083492279052734        0.125\n",
            "6       1.5814670324325562        0.39395833015441895\n",
            "\n",
            "7       2.2221968173980713        0.0637499988079071\n",
            "7       1.3200523853302002        0.503333330154419\n",
            "\n",
            "8       2.1965911388397217        0.10604166984558105\n",
            "8       1.1737908124923706        0.5531250238418579\n",
            "\n",
            "9       2.208747625350952        0.08645833283662796\n",
            "9       1.4427822828292847        0.4364583194255829\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ORE0aHmLhkL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}