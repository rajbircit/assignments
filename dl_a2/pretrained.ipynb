{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretrained.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajbircit/assignments/blob/main/dl_a2/pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbYaJtuDaTSE"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbaCPhN3m9aK"
      },
      "source": [
        "#### Show the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB1IYEiCVI31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbaeaa6e-b644-41db-f4b0-8e2693d98b4d"
      },
      "source": [
        "!nvidia-smi\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!df -h\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!free -m\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!lscpu\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "! ps -eo pmem,pcpu,vsize,pid,cmd | sort -k 1 -nr | head -5\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 25 13:15:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          69G   39G   30G  57% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "tmpfs           6.4G   24K  6.4G   1% /var/colab\n",
            "/dev/sda1        75G   41G   35G  54% /opt/bin\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          13021         579       10398           0        2042       12163\n",
            "Swap:             0           0           0\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2199.998\n",
            "BogoMIPS:            4399.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            " 0.8 24.8 690496      58 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-67aa7e6d-5e81-426c-b90f-dd9a9c6b85d9.json\n",
            " 0.4  4.0 193896      46 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --LargeFileManager.delete_to_trash=False --MappingKernelManager.root_dir=\"/content\"\n",
            " 0.3  1.6 337260       1 /tools/node/bin/node /datalab/web/app.js\n",
            " 0.1  0.0  94604      78 /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/debugpy/adapter --for-server 38051 --host 127.0.0.1 --port 18063 --server-access-token 9e7d3137802af0a7dd179d614c652c167b1017e15972e01360e3df573428c7bf\n",
            "%MEM %CPU    VSZ     PID CMD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Qj4WBS9_yI"
      },
      "source": [
        "## Some Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDtE1oSv972w",
        "outputId": "3e506fb8-9e01-40a9-ec3a-78d4f9bc05eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn import metrics, model_selection\n",
        "from statistics import mean, median\n",
        "from time import perf_counter\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier, SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import random\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import model_selection\n",
        "from sklearn import linear_model\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectFwe, chi2, f_classif\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhKgZdLnDXe"
      },
      "source": [
        "#### Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-qJFYSyXipf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import logging\n",
        "import sys\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import zipfile\n",
        "import h5py\n",
        "import gc\n",
        "import IPython\n",
        "\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "root = logging.getLogger()\n",
        "root.setLevel(logging.INFO)\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "root.addHandler(handler)\n",
        "\n",
        "random.seed(5)\n",
        "tf.random.set_seed(5)\n",
        "np.random.seed(5)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5dT_-3nTqYe"
      },
      "source": [
        "#### Mount Google Drive And Copy Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrZWOv9fTsF2",
        "outputId": "43237b33-2c71-4a86-869c-f2275f8f1815"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if (os.path.exists(\"/root/imagedata\")):\n",
        "    ret = shutil.rmtree(\"/root/imagedata\")\n",
        "os.mkdir(\"/root/imagedata\")\n",
        "shutil.copyfile( \\\n",
        "    \"/content/gdrive/MyDrive/DeepLearningAssignment2/earth_data.zip\",\n",
        "    \"/root/imagedata/earth_data.zip\")\n",
        "\n",
        "!cd /root/imagedata && unzip earth_data.zip && rm -f earth_data.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Archive:  earth_data.zip\n",
            "  inflating: earth_data.h5           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hK1gQ5CV1i-"
      },
      "source": [
        "## Code to plot graphs and remember histories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy4Y9ACqfea7"
      },
      "source": [
        "class Entry:\n",
        "    def __init__(self, loss, val_loss, accuracy, val_accuracy, best_accuracy, best_loss):\n",
        "        self.loss = loss\n",
        "        self.val_loss = val_loss\n",
        "        self.accuracy = accuracy\n",
        "        self.val_accuracy = val_accuracy\n",
        "        self.best_accuracy = best_accuracy\n",
        "        self.best_loss = best_loss\n",
        "\n",
        "class Plot:\n",
        "    def __init__(self):\n",
        "        self.history = {}\n",
        "        self.colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:blue', \\\n",
        "                       'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \\\n",
        "                       'tab:brown', 'tab:pink', 'tab:olive', 'tab:cyan']\n",
        "\n",
        "    def plot_history(self, history, N_EPOCHS, name, show=True):\n",
        "        if show:\n",
        "            N_EPOCHS = len(history.history[\"loss\"])\n",
        "            plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "            plt.xticks(np.arange(0, N_EPOCHS+1, 1.0))\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"loss\"], label=\"train loss\", color='blue', linestyle='solid')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"val_loss\"], label=\"val loss\", color='blue', linestyle='dashdot')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"accuracy\"], label=\"train acc\", color='red', linestyle='solid')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"val_accuracy\"], label=\"val acc\", color='red', linestyle='dashdot')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        best_val_acc = max(history.history['val_accuracy'])\n",
        "        index_best_val_accuracy = history.history['val_accuracy'].index(best_val_acc)\n",
        "        best_val_loss = min(history.history['val_loss'])\n",
        "        index_best_val_loss = history.history['val_loss'].index(best_val_loss)\n",
        "        if show:\n",
        "            print(f\"Best validation accuracy: {best_val_acc}, epoch = {index_best_val_accuracy}\")\n",
        "            print(f\"Best validation loss: {best_val_loss}, epoch = {index_best_val_loss}\")\n",
        "        entry = Entry(\\\n",
        "                      loss=history.history[\"loss\"],\\\n",
        "                      val_loss=history.history[\"val_loss\"],\\\n",
        "                      accuracy=history.history[\"accuracy\"],\\\n",
        "                      val_accuracy=history.history[\"val_accuracy\"],\\\n",
        "                      best_accuracy=best_val_acc,\n",
        "                      best_loss=best_val_loss)\n",
        "        self.history[name] = entry\n",
        "        gc.collect()\n",
        "\n",
        "    def superplot(self):\n",
        "        i = 0\n",
        "        plt.rcParams[\"figure.figsize\"] = [30, 10]\n",
        "        fig, ax = plt.subplots(1, 2)\n",
        "        def innerplot(self, ax, arr, text, linest):\n",
        "            ax.plot(np.arange(0, len(arr)), arr, label=text, color=self.colors[i], linestyle=linest)\n",
        "        for name, entry in self.history.items():\n",
        "            innerplot(self, ax[0], entry.loss, f\"{name}-loss\", \"solid\")\n",
        "            innerplot(self, ax[0], entry.val_loss, f\"{name}-val-loss\", \"dashdot\")\n",
        "            innerplot(self, ax[1], entry.accuracy, f\"{name}-accuracy\", \"solid\")\n",
        "            innerplot(self, ax[1], entry.val_accuracy, f\"{name}-val-accuracy\", \"dashdot\")\n",
        "            i += 1\n",
        "        ax[0].legend()\n",
        "        ax[1].legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7YJVg4Z8j3"
      },
      "source": [
        "## Extract train and test instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opVq7JewaAGA",
        "outputId": "c0b8eb27-6020-495d-b324-0d09d6fc5cf7"
      },
      "source": [
        "def loadDataH5():\n",
        "    with h5py.File('/root/imagedata/earth_data.h5','r') as hf:\n",
        "        trainX = np.array(hf.get('trainX'))\n",
        "        trainY = np.array(hf.get('trainY'))\n",
        "        valX = np.array(hf.get('valX'))\n",
        "        valY = np.array(hf.get('valY'))\n",
        "        print (trainX.shape,trainY.shape)\n",
        "        print (valX.shape,valY.shape)\n",
        "        return trainX, trainY, valX, valY\n",
        "\n",
        "trainX, trainY, valX, valY = loadDataH5()\n",
        "trainX = trainX / 255.0\n",
        "valX = valX / 255.0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19200, 64, 64, 3) (19200,)\n",
            "(4800, 64, 64, 3) (4800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewCcmX_SWH4W"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLKhKGMRWNfT"
      },
      "source": [
        "def decay_after_runs(N):\n",
        "    NRUNS = N\n",
        "    # We're sneaking this in, since this will be called at every epoch\n",
        "    # it also gives us a good way to force calls to gc() within the fit function\n",
        "    gc.collect()\n",
        "    def learning_rate_scheduler(epoch, lr):\n",
        "        if NRUNS < 0 or epoch < NRUNS:\n",
        "            return lr\n",
        "        else:\n",
        "            print(f\"Learning Rate: {lr} --> {lr * tf.math.exp(-1.0)}\")\n",
        "            return lr * tf.math.exp(-0.1)\n",
        "    return learning_rate_scheduler\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(decay_after_runs(20))\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\\\n",
        "                                                  monitor='val_loss',\\\n",
        "                                                  patience=3,\n",
        "                                                  verbose=1,\n",
        "                                                  mode='auto')\n",
        "early_stopping2 = tf.keras.callbacks.EarlyStopping(\\\n",
        "                                                  monitor='val_loss',\\\n",
        "                                                  patience=10,\n",
        "                                                  verbose=1,\n",
        "                                                  mode='auto')\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\\\n",
        "                                                 monitor='val_loss',\\\n",
        "                                                 factor=0.5,\\\n",
        "                                                 patience=3,\\\n",
        "                                                 min_lr=0.001)\n",
        "\n",
        "term_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
        "\n",
        "DRIVE_FOLDER = \"/content/gdrive/MyDrive/DeepLearningAssignment2\"\n",
        "\n",
        "def get_checkpoint_callback(name):\n",
        "    checkpoint_filepath = f\"{DRIVE_FOLDER}/ckp-{name}\"\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "    return model_checkpoint_callback\n",
        "\n",
        "\n",
        "def get_callbacks_decay_after(N, name=None):\n",
        "    if N == -2:\n",
        "        callback_array = [\\\n",
        "                        tf.keras.callbacks.LearningRateScheduler(\\\n",
        "                                                    decay_after_runs(-1)),\n",
        "                        early_stopping2,\n",
        "                        term_on_nan,\n",
        "                        ]\n",
        "    else:\n",
        "        callback_array = [\\\n",
        "                        tf.keras.callbacks.LearningRateScheduler(\\\n",
        "                                                    decay_after_runs(N)),\n",
        "                        early_stopping,\n",
        "                        term_on_nan,\n",
        "                        ]\n",
        "    if N > 0:\n",
        "        callback_array.append(reduce_lr)\n",
        "    if None != name:\n",
        "        callback_array.append(get_checkpoint_callback(name))\n",
        "    return callback_array"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVwezZ7dkTt_"
      },
      "source": [
        "## 1. Load the VGG Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtj-7DZA6iCn",
        "outputId": "e29fd327-ac25-4b02-9ebf-b1741046d6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vgg = tf.keras.applications.VGG16(\\\n",
        "                                  include_top=False,\\\n",
        "                                  weights='imagenet',\\\n",
        "                                  input_shape=trainX[0].shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr-DKVFt7mQn",
        "outputId": "3e8e76a7-068c-4bee-a791-45944a38ef88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vgg.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkYImuxJ7rjD"
      },
      "source": [
        "featuresTrain = vgg.predict(trainX)\n",
        "featuresVal = vgg.predict(valX)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1TUSHEy8piD",
        "outputId": "64c1c83b-ab9e-4b45-c1c3-4070ba3e7d78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "gc.collect()\n",
        "\n",
        "def feature_extraction_test(\\\n",
        "                            model_name:str,\\\n",
        "                            model,\\\n",
        "                            trainX,\\\n",
        "                            trainY,\\\n",
        "                            valX,\\\n",
        "                            valY\n",
        "                            ):\n",
        "    def secondary_classification(\\\n",
        "                                 model,\\\n",
        "                                 trainX,\\\n",
        "                                 trainY,\\\n",
        "                                 valX,\\\n",
        "                                 valY):\n",
        "        model.fit(trainX, trainY)\n",
        "        y_pred = model.predict(valX)\n",
        "        return accuracy_score(valY, y_pred)\n",
        "\n",
        "    basic_models = [\n",
        "        ('DecisionTreeClassifier', lambda: DecisionTreeClassifier(random_state=1)),\n",
        "        #('KNeighborsClassifier', lambda: KNeighborsClassifier()),\n",
        "        #('NearestCentroid', lambda: NearestCentroid()),\n",
        "        ('NaiveBayes', lambda: GaussianNB()),\n",
        "        #('Gaussian Process', lambda: GaussianProcessClassifier(random_state=1)),\n",
        "        #('Support Vector Machines', lambda: SVC(random_state=1)),\n",
        "        ('Random Forest', lambda: RandomForestClassifier(random_state=1)),\n",
        "        #('Ada Boost', lambda: AdaBoostClassifier(random_state=1)),\n",
        "        ('Gradient Boost', lambda: GradientBoostingClassifier()),\n",
        "        #('Linear Discriminant Analysis', lambda: LinearDiscriminantAnalysis()),\n",
        "        #('Quadriatic Discriminant Analysis', lambda: QuadraticDiscriminantAnalysis()),\n",
        "        #('Logistic Regression', lambda: LogisticRegression(random_state=1)),\n",
        "        #('Ridge Classifier', lambda: RidgeClassifier(random_state=1)),\n",
        "        #('Bagging Classifier', lambda: BaggingClassifier(random_state=1)),\n",
        "        #('SGD Classifier', lambda: SGDClassifier(random_state=1)),\n",
        "        #('Passive Aggressive Classifier', lambda: PassiveAggressiveClassifier(random_state=1)),\n",
        "        #('Perceptron', lambda: Perceptron(random_state=1)),\n",
        "        #('Multi-Layer Perceptron', lambda: MLPClassifier(random_state=1))\n",
        "    ]\n",
        "\n",
        "    m_names = []\n",
        "    m_acc = []\n",
        "    t_trainX = model.predict(trainX)\n",
        "    t_valX = model.predict(valX)\n",
        "    t_trainX = t_trainX.reshape(t_trainX.shape[0], -1)\n",
        "    t_valX = t_valX.reshape(t_valX.shape[0], -1)\n",
        "    scaler = StandardScaler().fit(t_trainX)\n",
        "    t_trainX = scaler.transform(t_trainX)\n",
        "    t_valX = scaler.transform(t_valX)\n",
        "\n",
        "    for (n, m) in basic_models:\n",
        "        print(f\"Training model {n}\")\n",
        "        accuracy = secondary_classification(m(),\\\n",
        "                                            t_trainX,\\\n",
        "                                            trainY,\\\n",
        "                                            t_valX,\\\n",
        "                                            valY)\n",
        "        print(f\"Accuracy = {accuracy}\")\n",
        "        m_names.append(n)\n",
        "        m_acc.append(accuracy)\n",
        "        \n",
        "    df = pd.DataFrame({\"Model\": pd.Series(m_names), \"accuracy\": pd.Series(m_acc)})\n",
        "    p = sns.barplot(y='Model', x='accuracy', data=df, orient='h')\n",
        "    p.set_title(model_name)\n",
        "    plt.show()\n",
        "    return m_names, m_acc\n",
        "\n",
        "    \n",
        "\n",
        "vgg16 = tf.keras.applications.VGG16(\\\n",
        "                                  include_top=False,\\\n",
        "                                  weights='imagenet',\\\n",
        "                                  input_shape=trainX[0].shape)\n",
        "vg16_names, vgg16_acc = feature_extraction_test(\"VGG16\", vgg16, trainX, trainY, valX, valY)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model DecisionTreeClassifier\n",
            "Accuracy = 0.6385416666666667\n",
            "Training model NaiveBayes\n",
            "Accuracy = 0.5022916666666667\n",
            "Training model Random Forest\n",
            "Accuracy = 0.8183333333333334\n",
            "Training model Gradient Boost\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfVB5jkvMBjQ"
      },
      "source": [
        "vgg19 = tf.keras.applications.VGG19(\\\n",
        "                                    include_top=False,\\\n",
        "                                    weights='imagenet',\\\n",
        "                                    input_shape=trainX[0].shape)\n",
        "vgg19_names, vgg19_acc = features_extraction_test(\"VGG19\", vgg19, trainX, trainY, valX, valY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeM50mgyAq64"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV96j3BU-pU2"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.DataFrame({\"name\": pd.Series(['a', 'b']), \"score\": pd.Series([1, 2])})\n",
        "\n",
        "sns.barplot(y='name', x='score', data=df, orient='h')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53pNJkv6Bw_w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}