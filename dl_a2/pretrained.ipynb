{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretrained.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajbircit/assignments/blob/main/dl_a2/pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbYaJtuDaTSE"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbaCPhN3m9aK"
      },
      "source": [
        "#### Show the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB1IYEiCVI31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "027c51b3-e859-4209-d6df-e4cccce1dc70"
      },
      "source": [
        "!nvidia-smi\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!df -h\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!free -m\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "!lscpu\n",
        "print()\n",
        "print()\n",
        "print('=' * 80)\n",
        "print()\n",
        "print()\n",
        "! ps -eo pmem,pcpu,vsize,pid,cmd | sort -k 1 -nr | head -5\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 25 11:03:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          69G   39G   30G  57% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "/dev/sda1        75G   41G   35G  54% /opt/bin\n",
            "tmpfs           6.4G   24K  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          13021         692       10280           0        2048       12066\n",
            "Swap:             0           0           0\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               63\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2299.998\n",
            "BogoMIPS:            4599.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            46080K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            " 2.6 10.9 1715888     58 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-ecc1663c-ae93-4fa6-b35b-576febc0702b.json\n",
            " 0.4  0.3 193896      47 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --LargeFileManager.delete_to_trash=False --MappingKernelManager.root_dir=\"/content\"\n",
            " 0.3  0.3 337516       1 /tools/node/bin/node /datalab/web/app.js\n",
            " 0.1  0.0 127392      78 /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/debugpy/adapter --for-server 43451 --host 127.0.0.1 --port 17661 --server-access-token 498e782776de26bcb77dfd33575463fb4b93642bb8ce78309bdb9c0d8584bf55\n",
            "%MEM %CPU    VSZ     PID CMD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhKgZdLnDXe"
      },
      "source": [
        "#### Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-qJFYSyXipf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import logging\n",
        "import sys\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import zipfile\n",
        "import h5py\n",
        "import gc\n",
        "import IPython\n",
        "\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "root = logging.getLogger()\n",
        "root.setLevel(logging.INFO)\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "root.addHandler(handler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5dT_-3nTqYe"
      },
      "source": [
        "#### Mount Google Drive And Copy Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrZWOv9fTsF2",
        "outputId": "cd02f126-4d13-47ff-8d7f-45f0c5573f35"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if (os.path.exists(\"/root/imagedata\")):\n",
        "    ret = shutil.rmtree(\"/root/imagedata\")\n",
        "os.mkdir(\"/root/imagedata\")\n",
        "shutil.copyfile( \\\n",
        "    \"/content/gdrive/MyDrive/DeepLearningAssignment2/earth_data.zip\",\n",
        "    \"/root/imagedata/earth_data.zip\")\n",
        "\n",
        "!cd /root/imagedata && unzip earth_data.zip && rm -f earth_data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Archive:  earth_data.zip\n",
            "  inflating: earth_data.h5           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hK1gQ5CV1i-"
      },
      "source": [
        "## Code to plot graphs and remember histories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy4Y9ACqfea7"
      },
      "source": [
        "class Entry:\n",
        "    def __init__(self, loss, val_loss, accuracy, val_accuracy, best_accuracy, best_loss):\n",
        "        self.loss = loss\n",
        "        self.val_loss = val_loss\n",
        "        self.accuracy = accuracy\n",
        "        self.val_accuracy = val_accuracy\n",
        "        self.best_accuracy = best_accuracy\n",
        "        self.best_loss = best_loss\n",
        "\n",
        "class Plot:\n",
        "    def __init__(self):\n",
        "        self.history = {}\n",
        "        self.colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:blue', \\\n",
        "                       'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \\\n",
        "                       'tab:brown', 'tab:pink', 'tab:olive', 'tab:cyan']\n",
        "\n",
        "    def plot_history(self, history, N_EPOCHS, name, show=True):\n",
        "        if show:\n",
        "            N_EPOCHS = len(history.history[\"loss\"])\n",
        "            plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "            plt.xticks(np.arange(0, N_EPOCHS+1, 1.0))\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"loss\"], label=\"train loss\", color='blue', linestyle='solid')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"val_loss\"], label=\"val loss\", color='blue', linestyle='dashdot')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"accuracy\"], label=\"train acc\", color='red', linestyle='solid')\n",
        "            plt.plot(np.arange(0, N_EPOCHS), history.history[\"val_accuracy\"], label=\"val acc\", color='red', linestyle='dashdot')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        best_val_acc = max(history.history['val_accuracy'])\n",
        "        index_best_val_accuracy = history.history['val_accuracy'].index(best_val_acc)\n",
        "        best_val_loss = min(history.history['val_loss'])\n",
        "        index_best_val_loss = history.history['val_loss'].index(best_val_loss)\n",
        "        if show:\n",
        "            print(f\"Best validation accuracy: {best_val_acc}, epoch = {index_best_val_accuracy}\")\n",
        "            print(f\"Best validation loss: {best_val_loss}, epoch = {index_best_val_loss}\")\n",
        "        entry = Entry(\\\n",
        "                      loss=history.history[\"loss\"],\\\n",
        "                      val_loss=history.history[\"val_loss\"],\\\n",
        "                      accuracy=history.history[\"accuracy\"],\\\n",
        "                      val_accuracy=history.history[\"val_accuracy\"],\\\n",
        "                      best_accuracy=best_val_acc,\n",
        "                      best_loss=best_val_loss)\n",
        "        self.history[name] = entry\n",
        "        gc.collect()\n",
        "\n",
        "    def superplot(self):\n",
        "        i = 0\n",
        "        plt.rcParams[\"figure.figsize\"] = [30, 10]\n",
        "        fig, ax = plt.subplots(1, 2)\n",
        "        def innerplot(self, ax, arr, text, linest):\n",
        "            ax.plot(np.arange(0, len(arr)), arr, label=text, color=self.colors[i], linestyle=linest)\n",
        "        for name, entry in self.history.items():\n",
        "            innerplot(self, ax[0], entry.loss, f\"{name}-loss\", \"solid\")\n",
        "            innerplot(self, ax[0], entry.val_loss, f\"{name}-val-loss\", \"dashdot\")\n",
        "            innerplot(self, ax[1], entry.accuracy, f\"{name}-accuracy\", \"solid\")\n",
        "            innerplot(self, ax[1], entry.val_accuracy, f\"{name}-val-accuracy\", \"dashdot\")\n",
        "            i += 1\n",
        "        ax[0].legend()\n",
        "        ax[1].legend()\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7YJVg4Z8j3"
      },
      "source": [
        "## Extract train and test instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opVq7JewaAGA",
        "outputId": "d9a49779-0a5f-412c-c41c-21354170d42e"
      },
      "source": [
        "def loadDataH5():\n",
        "    with h5py.File('/root/imagedata/earth_data.h5','r') as hf:\n",
        "        trainX = np.array(hf.get('trainX'))\n",
        "        trainY = np.array(hf.get('trainY'))\n",
        "        valX = np.array(hf.get('valX'))\n",
        "        valY = np.array(hf.get('valY'))\n",
        "        print (trainX.shape,trainY.shape)\n",
        "        print (valX.shape,valY.shape)\n",
        "        return trainX, trainY, valX, valY\n",
        "\n",
        "trainX, trainY, valX, valY = loadDataH5()\n",
        "trainX = trainX / 255.0\n",
        "valX = valX / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19200, 64, 64, 3) (19200,)\n",
            "(4800, 64, 64, 3) (4800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewCcmX_SWH4W"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLKhKGMRWNfT"
      },
      "source": [
        "def decay_after_runs(N):\n",
        "    NRUNS = N\n",
        "    # We're sneaking this in, since this will be called at every epoch\n",
        "    # it also gives us a good way to force calls to gc() within the fit function\n",
        "    gc.collect()\n",
        "    def learning_rate_scheduler(epoch, lr):\n",
        "        if NRUNS < 0 or epoch < NRUNS:\n",
        "            return lr\n",
        "        else:\n",
        "            print(f\"Learning Rate: {lr} --> {lr * tf.math.exp(-1.0)}\")\n",
        "            return lr * tf.math.exp(-0.1)\n",
        "    return learning_rate_scheduler\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(decay_after_runs(20))\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\\\n",
        "                                                  monitor='val_loss',\\\n",
        "                                                  patience=3,\n",
        "                                                  verbose=1,\n",
        "                                                  mode='auto')\n",
        "early_stopping2 = tf.keras.callbacks.EarlyStopping(\\\n",
        "                                                  monitor='val_loss',\\\n",
        "                                                  patience=10,\n",
        "                                                  verbose=1,\n",
        "                                                  mode='auto')\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\\\n",
        "                                                 monitor='val_loss',\\\n",
        "                                                 factor=0.5,\\\n",
        "                                                 patience=3,\\\n",
        "                                                 min_lr=0.001)\n",
        "\n",
        "term_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
        "\n",
        "DRIVE_FOLDER = \"/content/gdrive/MyDrive/DeepLearningAssignment2\"\n",
        "\n",
        "def get_checkpoint_callback(name):\n",
        "    checkpoint_filepath = f\"{DRIVE_FOLDER}/ckp-{name}\"\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "    return model_checkpoint_callback\n",
        "\n",
        "\n",
        "def get_callbacks_decay_after(N, name=None):\n",
        "    if N == -2:\n",
        "        callback_array = [\\\n",
        "                        tf.keras.callbacks.LearningRateScheduler(\\\n",
        "                                                    decay_after_runs(-1)),\n",
        "                        early_stopping2,\n",
        "                        term_on_nan,\n",
        "                        ]\n",
        "    else:\n",
        "        callback_array = [\\\n",
        "                        tf.keras.callbacks.LearningRateScheduler(\\\n",
        "                                                    decay_after_runs(N)),\n",
        "                        early_stopping,\n",
        "                        term_on_nan,\n",
        "                        ]\n",
        "    if N > 0:\n",
        "        callback_array.append(reduce_lr)\n",
        "    if None != name:\n",
        "        callback_array.append(get_checkpoint_callback(name))\n",
        "    return callback_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWZ5Iw4skLdB"
      },
      "source": [
        "# Question 1 Part A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVwezZ7dkTt_"
      },
      "source": [
        "## 1. Build a model generator"
      ]
    }
  ]
}